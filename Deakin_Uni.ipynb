{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4cdf5e-c2f7-4ea6-ac63-6cbc6929a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb601ab2-19da-440d-b6a7-47c02bf7ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "\n",
    "def loadDataset():\n",
    "    data = []\n",
    "    labels = []\n",
    "    root = '/home/rkarim/Training_data/'\n",
    "\n",
    "    for rootName, dirName, fileNames in os.walk(root):\n",
    "        if not rootName == root:\n",
    "            label = rootName.split('/')[-1]\n",
    "            for fileName in fileNames:\n",
    "                if fileName.endswith('.jpg'):\n",
    "                    img = load_img(os.path.join(rootName, fileName), target_size=(32, 32))  # Ensure uniform size\n",
    "                    img = img_to_array(img)\n",
    "                    data.append(img)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "x_data, y_data = loadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afffcd6-afb1-44c2-b963-205b83cd1678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "\n",
    "x_data = x_data.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04765262-6358-4e47-b6fe-4ec1d21f5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting labels into Numbers\n",
    "\n",
    "unique_labels = np.unique(y_data)\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "y_data = np.array([label_to_index[label] for label in y_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1e2fe-7877-4940-95b8-9aca83097111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining input shape\n",
    "\n",
    "input_shape = x_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd39d95-2690-4d45-a306-637593316014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining autooencoder model\n",
    "\n",
    "input_img = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6feed28-58a0-4541-91ec-9dd158ffe23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "for _ in range(11):\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf7b1bd-eb50-40c6-a2e9-11bb7f8b4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "\n",
    "x = encoded\n",
    "for _ in range(11):\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c636fe8d-0910-4e9a-a0a4-38f8b4b4af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and compiling the model\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a50712-0388-4a92-8a1b-f7d480008f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "\n",
    "split_idx = int(0.8 * len(x_data))\n",
    "x_train, x_test = x_data[:split_idx], x_data[split_idx:]\n",
    "y_train, y_test = y_data[:split_idx], y_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6d66f-7181-4939-9980-ff0e98387a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Autoencoder\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, verbose=1),\n",
    "    ModelCheckpoint('model.h5', save_best_only=True, verbose=1)\n",
    "]\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a16af-1e7d-4f62-8431-408f59f4c4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41729801-0540-44da-802b-10b157b215ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the encoder model\n",
    "\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1271a87-d918-49ea-89ff-71f21685a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting encoded data\n",
    "\n",
    "x_encoded = encoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f1e17-1216-4ca9-aace-3bfb7781a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening the data into 2D for K-means\n",
    "\n",
    "x_encoded_reshaped = x_encoded.reshape(x_encoded.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d7a0a-d0a1-428b-ac22-df3c70a3ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying kmeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=len(unique_labels))\n",
    "clusters = kmeans.fit_predict(x_encoded_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44137a96-b4b1-495e-b8bd-c3b7001a6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measuring ARI\n",
    "\n",
    "ari = adjusted_rand_score(y_train, clusters)\n",
    "print(f'Adjusted Rand Index (ARI): {ari}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
